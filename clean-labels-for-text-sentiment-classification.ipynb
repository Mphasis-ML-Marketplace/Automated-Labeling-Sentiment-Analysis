{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a8906fc",
   "metadata": {},
   "source": [
    "## Get clean sentiment class labels using clean-sentiment-classification-labels Algorithm from AWS Marketplace \n",
    "\n",
    "The solution uses a pre-trained deep learning and confidence learning based modelling approach to provide clean sentiment class labels to your unlabelled dataset.\n",
    "\n",
    "This sample notebook shows you how to execute clean-sentiment-classification-labels Algorithm from AWS Marketplace \n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "#### Pre-requisites:\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. Some hands-on experience using [Amazon SageMaker](https://aws.amazon.com/sagemaker/).\n",
    "1. To use this algorithm successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to For Seller to update: clean-sentiment-classification-labels. \n",
    "\n",
    "#### Contents:\n",
    "1. [Subscribe to the algorithm](#1.-Subscribe-to-the-algorithm)\n",
    "1. [Prepare dataset](#2.-Prepare-dataset)\n",
    "\t1. [Dataset format expected by the algorithm](#A.-Dataset-format-expected-by-the-algorithm)\n",
    "\t1. [Configure dataset](#B.-Configure-dataset)\n",
    "\t1. [Upload datasets to Amazon S3](#C.-Upload-datasets-to-Amazon-S3)\n",
    "1. [Execute optimization model](#3.-Execute-optimization-model)\n",
    "\t1. [Set up environment](#3.1-Set-up-environment)\n",
    "\t1. [Execute model](#3.2-Execute-model)\n",
    "    1. [Visualize Output](#3.3-Inspect-the-Output-in-S3)\n",
    "1. [Clean-up](#4.-Clean-up)\n",
    "\t1. [Unsubscribe to the listing (optional)](#Unsubscribe-to-the-listing-(optional))\n",
    "\n",
    "\n",
    "#### Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f263eca",
   "metadata": {},
   "source": [
    "### 1. Subscribe to the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0188d0b5",
   "metadata": {},
   "source": [
    "To subscribe to the algorithm:\n",
    "1. Open the algorithm listing page **Clean Sentiment Classification Labels**\n",
    "1. On the AWS Marketplace listing,  click on **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you agree with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn**. This is the algorithm ARN that you need to specify while training a custom ML model. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ece4ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_arn = \"arn:aws:sagemaker:us-east-2:786796469737:algorithm/clean-labels-for-text-sentiment-classification\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81230eda",
   "metadata": {},
   "source": [
    "### 2. Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "568b9452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json \n",
    "import uuid\n",
    "import boto3\n",
    "import pickle\n",
    "import base64\n",
    "import tarfile\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import urllib.request\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import sagemaker as sage\n",
    "from sagemaker import ModelPackage\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c502a0",
   "metadata": {},
   "source": [
    "#### A. Dataset format expected by the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2ee582",
   "metadata": {},
   "source": [
    "The algorithm requires data in the format as described for best results:\n",
    "* Input File name should be input.csv\n",
    "* The input data files must contain a text column and should be unlabelled (no sentiment class labels).\n",
    "* For detailed instructions, please refer sample notebook and algorithm input details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70b07bc",
   "metadata": {},
   "source": [
    "#### B. Configure dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ccdf68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset=\"Input/input.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2191c4f4",
   "metadata": {},
   "source": [
    "#### C. Upload datasets to Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e0b216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d456376",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sage.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fff34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training input location\n",
    "common_prefix = \"clean_labels_for_text_sentiment_classification\"\n",
    "training_input_prefix = common_prefix + \"/training-input-data\"\n",
    "TRAINING_WORKDIR = \"Input\" #Input directory in Jupyter Server\n",
    "training_input = sagemaker_session.upload_data(TRAINING_WORKDIR, key_prefix=training_input_prefix) #uploads data from jupyter server to S3\n",
    "print(\"Training input uploaded to \" + training_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb679191",
   "metadata": {},
   "source": [
    "## 3. Execute the training process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55f2a54",
   "metadata": {},
   "source": [
    "Now that dataset is available in an accessible Amazon S3 bucket, we are ready to execute a training pipeline to get clean sentiment class labels using clean-sentiment-classification-labels Algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4284f615",
   "metadata": {},
   "source": [
    "### 3.1 Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6085fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_location = 's3://{}/clean-label/{}'.format(bucket, 'output')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5865b68",
   "metadata": {},
   "source": [
    "### 3.2 Execute model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c4c45a",
   "metadata": {},
   "source": [
    "For information on creating an `Estimator` object, see [documentation](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74934c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_instance_type=\"ml.m5.4xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd37ab90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-10 03:11:10 Starting - Starting the training job...\n",
      "2022-10-10 03:11:33 Starting - Preparing the instances for trainingProfilerReport-1665371470: InProgress\n",
      "......\n",
      "2022-10-10 03:12:33 Downloading - Downloading input data\n",
      "2022-10-10 03:12:33 Training - Downloading the training image...\n",
      "2022-10-10 03:13:09 Training - Training image download completed. Training in progress...\u001b[34m2022-10-10 03:13:12.836908: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2022-10-10 03:13:12.836949: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2022-10-10 03:13:15.618202: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2022-10-10 03:13:15.618224: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2022-10-10 03:13:15.618243: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-181-185.us-east-2.compute.internal): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2022-10-10 03:13:15.618506: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\u001b[0m\n",
      "\u001b[34mTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\u001b[0m\n",
      "\u001b[34mAll model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\u001b[0m\n",
      "\u001b[34mAll the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at huggingface_artifacts/tf_model.\u001b[0m\n",
      "\u001b[34mIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\u001b[0m\n",
      "\u001b[34m2022-10-10 03:13:44.019839: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\u001b[0m\n",
      "\u001b[34mWARNING:absl:Found untraced functions such as encoder_layer_call_and_return_conditional_losses, encoder_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, dense_layer_call_and_return_conditional_losses while saving (showing 5 of 1055). These functions will not be directly callable after loading.\u001b[0m\n",
      "\u001b[34m2022-10-10 03:14:25.369130: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\u001b[0m\n",
      "\u001b[34mEpoch 1/2\u001b[0m\n",
      "\u001b[34m#0151/1 [==============================] - ETA: 0s - loss: 1.1632 - categorical_accuracy: 0.1364#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151/1 [==============================] - 14s 14s/step - loss: 1.1632 - categorical_accuracy: 0.1364\u001b[0m\n",
      "\u001b[34mEpoch 2/2\u001b[0m\n",
      "\u001b[34m#0151/1 [==============================] - ETA: 0s - loss: 1.6263 - categorical_accuracy: 1.0000#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151/1 [==============================] - 3s 3s/step - loss: 1.6263 - categorical_accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m#0151/1 [==============================] - ETA: 0s#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151/1 [==============================] - 2s 2s/step\u001b[0m\n",
      "\u001b[34mWARNING:absl:Found untraced functions such as encoder_layer_call_and_return_conditional_losses, encoder_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, dense_layer_call_and_return_conditional_losses while saving (showing 5 of 1055). These functions will not be directly callable after loading.\u001b[0m\n",
      "\u001b[34mEpoch 1/2\u001b[0m\n",
      "\u001b[34m#0151/1 [==============================] - ETA: 0s - loss: 1.0033 - categorical_accuracy: 0.2174#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151/1 [==============================] - 17s 17s/step - loss: 1.0033 - categorical_accuracy: 0.2174\u001b[0m\n",
      "\u001b[34mEpoch 2/2\u001b[0m\n",
      "\u001b[34m#0151/1 [==============================] - ETA: 0s - loss: 1.7507 - categorical_accuracy: 1.0000#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151/1 [==============================] - 3s 3s/step - loss: 1.7507 - categorical_accuracy: 1.0000\u001b[0m\n",
      "\u001b[34m#0151/1 [==============================] - ETA: 0s#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151/1 [==============================] - 2s 2s/step\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.6/dist-packages/cleanlab/filter.py:206: UserWarning: May not flag all label issues in class: 2, it has too few examples (see `min_examples_per_class` argument)\n",
      "  f\"May not flag all label issues in class: {k}, it has too few examples (see `min_examples_per_class` argument)\"\u001b[0m\n",
      "\u001b[34mEpoch 1/2\u001b[0m\n",
      "\u001b[34m#0151/1 [==============================] - ETA: 0s - loss: 4.5923 - categorical_accuracy: 0.2000#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151/1 [==============================] - 20s 20s/step - loss: 4.5923 - categorical_accuracy: 0.2000\u001b[0m\n",
      "\u001b[34mEpoch 2/2\u001b[0m\n",
      "\u001b[34m#0151/1 [==============================] - ETA: 0s - loss: 3.2526 - categorical_accuracy: 0.9000#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0151/1 [==============================] - 4s 4s/step - loss: 3.2526 - categorical_accuracy: 0.9000\u001b[0m\n",
      "\u001b[34m#0151/2 [==============>...............] - ETA: 3s#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - ETA: 0s#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#0152/2 [==============================] - 4s 570ms/step\n",
      " ################################################\u001b[0m\n",
      "\u001b[34mClean labels are better than base labels.\n",
      " ################################################\u001b[0m\n",
      "\n",
      "2022-10-10 03:16:35 Uploading - Uploading generated training model\n",
      "2022-10-10 03:17:14 Completed - Training job completed\n",
      "ProfilerReport-1665371470: NoIssuesFound\n",
      "Training seconds: 267\n",
      "Billable seconds: 267\n"
     ]
    }
   ],
   "source": [
    "#Create an estimator object for running a training job\n",
    "estimator = sage.algorithm.AlgorithmEstimator(\n",
    "    algorithm_arn=algo_arn,\n",
    "    base_job_name=\"clean-sentiment-classification-labels-algo\",\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=training_instance_type,\n",
    "    input_mode=\"File\",\n",
    "    output_path=output_location,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type\n",
    ")\n",
    "\n",
    "#Run the training job.\n",
    "estimator.fit({\"training\": training_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f6fd00",
   "metadata": {},
   "source": [
    "See this [blog-post](https://aws.amazon.com/blogs/machine-learning/easily-monitor-and-visualize-metrics-while-training-models-on-amazon-sagemaker/) for more information how to visualize metrics during the process. You can also open the training job from [Amazon SageMaker console](https://console.aws.amazon.com/sagemaker/home?#/jobs/) and monitor the metrics/logs in **Monitor** section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034753d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output is available on following path\n",
    "estimator.output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d5ce09",
   "metadata": {},
   "source": [
    "## Note: Inferencing is done within training pipeline. Real time inference endpoint/batch transform job is not required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4610f3a",
   "metadata": {},
   "source": [
    "### 3.3 Inspect the Output in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b8c2be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_url = urlparse(estimator.output_path)\n",
    "bucket_name = parsed_url.netloc\n",
    "file_key = parsed_url.path[1:]+'/'+estimator.latest_training_job.job_name+'/output/'+\"model.tar.gz\"\n",
    "\n",
    "s3_client = sagemaker_session.boto_session.client('s3')\n",
    "response = s3_client.get_object(Bucket = sagemaker_session.default_bucket(), Key = file_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26744eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketFolder = estimator.output_path.rsplit('/')[3] +'/output/'+ estimator.latest_training_job.job_name+'/output/'+\"model.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7f02e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file loaded from bucket\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "s3_conn = boto3.client(\"s3\")\n",
    "bucket_name=bucket\n",
    "with open('output.tar.gz', 'wb') as f:\n",
    "    s3_conn.download_fileobj(bucket_name, bucketFolder, f)\n",
    "    print(\"Output file loaded from bucket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1163f09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open('output.tar.gz') as file:\n",
    "    file.extractall('./output')\n",
    "\n",
    "output_path = \"output/\"\n",
    "with open(os.path.join(output_path, \"output.pickle\"), \"rb+\") as infile:\n",
    "    output = pickle.load(infile)\n",
    "\n",
    "output.to_csv(output_path + \"output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "759b7014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>verified</th>\n",
       "      <th>votes</th>\n",
       "      <th>text</th>\n",
       "      <th>headlines</th>\n",
       "      <th>base_label</th>\n",
       "      <th>clean_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Today I received  1 Fl. Oz, Natures Balance Al...</td>\n",
       "      <td>*Product sent not as shown</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This does not work for me like it said on webs...</td>\n",
       "      <td>Ability Superstore Can-Pull Including Soda-Snap</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I have used Cross reading glasses for a couple...</td>\n",
       "      <td>They were sold out</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>My hair is light/medium brown and I just wante...</td>\n",
       "      <td>Runs very dark....</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Didn't include any pouch. Its wonderful and ef...</td>\n",
       "      <td>Liar...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  verified  votes  \\\n",
       "0           0         0      1   \n",
       "1           1         0      0   \n",
       "2           2         1      0   \n",
       "3           3         1      3   \n",
       "4           4         0      3   \n",
       "\n",
       "                                                text  \\\n",
       "0  Today I received  1 Fl. Oz, Natures Balance Al...   \n",
       "1  This does not work for me like it said on webs...   \n",
       "2  I have used Cross reading glasses for a couple...   \n",
       "3  My hair is light/medium brown and I just wante...   \n",
       "4  Didn't include any pouch. Its wonderful and ef...   \n",
       "\n",
       "                                         headlines  base_label  clean_label  \n",
       "0                       *Product sent not as shown           1            2  \n",
       "1  Ability Superstore Can-Pull Including Soda-Snap           0            2  \n",
       "2                               They were sold out           2            2  \n",
       "3                               Runs very dark....           1            2  \n",
       "4                                          Liar...           1            2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22e5811",
   "metadata": {},
   "source": [
    "### 4. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02cb842",
   "metadata": {},
   "source": [
    "#### Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b890dc60",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the algorithm, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
