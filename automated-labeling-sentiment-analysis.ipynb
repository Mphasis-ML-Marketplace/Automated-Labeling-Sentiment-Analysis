{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a8906fc",
   "metadata": {},
   "source": [
    "## Get clean sentiment class labels using Automated-Labeling-sentiment-analysis Algorithm from AWS Marketplace \n",
    "\n",
    "The solution uses a pre-trained deep learning and confidence learning based modelling approach to provide clean sentiment class labels to your unlabelled dataset.\n",
    "\n",
    "This sample notebook shows you how to execute Automated-Labeling-sentiment-analysis Algorithm from AWS Marketplace \n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "#### Pre-requisites:\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. Some hands-on experience using [Amazon SageMaker](https://aws.amazon.com/sagemaker/).\n",
    "1. To use this algorithm successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to For Seller to update: clean-sentiment-classification-labels. \n",
    "\n",
    "#### Contents:\n",
    "1. [Subscribe to the algorithm](#1.-Subscribe-to-the-algorithm)\n",
    "1. [Prepare dataset](#2.-Prepare-dataset)\n",
    "\t1. [Dataset format expected by the algorithm](#A.-Dataset-format-expected-by-the-algorithm)\n",
    "\t1. [Configure dataset](#B.-Configure-dataset)\n",
    "\t1. [Upload datasets to Amazon S3](#C.-Upload-datasets-to-Amazon-S3)\n",
    "1. [Execute optimization model](#3.-Execute-optimization-model)\n",
    "\t1. [Set up environment](#3.1-Set-up-environment)\n",
    "\t1. [Execute model](#3.2-Execute-model)\n",
    "    1. [Visualize Output](#3.3-Inspect-the-Output-in-S3)\n",
    "1. [Clean-up](#4.-Clean-up)\n",
    "\t1. [Unsubscribe to the listing (optional)](#Unsubscribe-to-the-listing-(optional))\n",
    "\n",
    "\n",
    "#### Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f263eca",
   "metadata": {},
   "source": [
    "### 1. Subscribe to the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0188d0b5",
   "metadata": {},
   "source": [
    "To subscribe to the algorithm:\n",
    "1. Open the algorithm listing page **Automated Labeling: Sentiment Analysis**\n",
    "1. On the AWS Marketplace listing,  click on **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you agree with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn**. This is the algorithm ARN that you need to specify while training a custom ML model. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece4ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_arn = \"clean-labels-for-text-sentiment-classification\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81230eda",
   "metadata": {},
   "source": [
    "### 2. Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568b9452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json \n",
    "import uuid\n",
    "import boto3\n",
    "import pickle\n",
    "import base64\n",
    "import tarfile\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import urllib.request\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import sagemaker as sage\n",
    "from sagemaker import ModelPackage\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c502a0",
   "metadata": {},
   "source": [
    "#### A. Dataset format expected by the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2ee582",
   "metadata": {},
   "source": [
    "The algorithm requires data in the format as described for best results:\n",
    "* Input File name should be input.csv\n",
    "* The input data files must contain a text column and should be unlabelled (no sentiment class labels).\n",
    "* For detailed instructions, please refer sample notebook and algorithm input details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70b07bc",
   "metadata": {},
   "source": [
    "#### B. Configure dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccdf68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset=\"Input/input.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2191c4f4",
   "metadata": {},
   "source": [
    "#### C. Upload datasets to Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0b216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d456376",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sage.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fff34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training input location\n",
    "common_prefix = \"clean_labels_for_text_sentiment_classification\"\n",
    "training_input_prefix = common_prefix + \"/training-input-data\"\n",
    "TRAINING_WORKDIR = \"Input\" #Input directory in Jupyter Server\n",
    "training_input = sagemaker_session.upload_data(TRAINING_WORKDIR, key_prefix=training_input_prefix) #uploads data from jupyter server to S3\n",
    "print(\"Training input uploaded to \" + training_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb679191",
   "metadata": {},
   "source": [
    "## 3. Execute the training process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55f2a54",
   "metadata": {},
   "source": [
    "Now that dataset is available in an accessible Amazon S3 bucket, we are ready to execute a training pipeline to get clean sentiment class labels using clean-sentiment-classification-labels Algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4284f615",
   "metadata": {},
   "source": [
    "### 3.1 Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6085fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_location = 's3://{}/clean_labels_for_text_sentiment_classification/{}'.format(bucket, 'output')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5865b68",
   "metadata": {},
   "source": [
    "### 3.2 Execute model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c4c45a",
   "metadata": {},
   "source": [
    "For information on creating an `Estimator` object, see [documentation](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74934c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_instance_type=\"ml.m5.4xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd37ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an estimator object for running a training job\n",
    "estimator = sage.algorithm.AlgorithmEstimator(\n",
    "    algorithm_arn=algo_arn,\n",
    "    base_job_name=\"clean-sentiment-classification-labels-algo\",\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type=training_instance_type,\n",
    "    input_mode=\"File\",\n",
    "    output_path=output_location,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type\n",
    ")\n",
    "\n",
    "#Run the training job.\n",
    "estimator.fit({\"training\": training_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f6fd00",
   "metadata": {},
   "source": [
    "See this [blog-post](https://aws.amazon.com/blogs/machine-learning/easily-monitor-and-visualize-metrics-while-training-models-on-amazon-sagemaker/) for more information how to visualize metrics during the process. You can also open the training job from [Amazon SageMaker console](https://console.aws.amazon.com/sagemaker/home?#/jobs/) and monitor the metrics/logs in **Monitor** section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034753d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output is available on following path\n",
    "estimator.output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d5ce09",
   "metadata": {},
   "source": [
    "## Note: Inferencing is done within training pipeline. Real time inference endpoint/batch transform job is not required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4610f3a",
   "metadata": {},
   "source": [
    "### 3.3 Inspect the Output in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8c2be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_url = urlparse(estimator.output_path)\n",
    "bucket_name = parsed_url.netloc\n",
    "file_key = parsed_url.path[1:]+'/'+estimator.latest_training_job.job_name+'/output/'+\"model.tar.gz\"\n",
    "\n",
    "s3_client = sagemaker_session.boto_session.client('s3')\n",
    "response = s3_client.get_object(Bucket = sagemaker_session.default_bucket(), Key = file_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26744eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketFolder = estimator.output_path.rsplit('/')[3] +'/output/'+ estimator.latest_training_job.job_name+'/output/'+\"model.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f02e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_conn = boto3.client(\"s3\")\n",
    "bucket_name=bucket\n",
    "with open('output.tar.gz', 'wb') as f:\n",
    "    s3_conn.download_fileobj(bucket_name, bucketFolder, f)\n",
    "    print(\"Output file loaded from bucket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1163f09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open('output.tar.gz') as file:\n",
    "    file.extractall('./output')\n",
    "\n",
    "output_path = \"output/\"\n",
    "with open(os.path.join(output_path, \"output.pickle\"), \"rb+\") as infile:\n",
    "    output = pickle.load(infile)\n",
    "\n",
    "output.to_csv(output_path + \"output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759b7014",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22e5811",
   "metadata": {},
   "source": [
    "### 4. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02cb842",
   "metadata": {},
   "source": [
    "#### Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b890dc60",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the algorithm, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('clean_label')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d17eaa6da6d22e5ba4039b8dd727e1e876629a34d751bdeeff55d2be26ed784"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
